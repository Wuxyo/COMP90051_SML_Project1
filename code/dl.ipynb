{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f63280f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class label:  1  Number: 578\n",
      "Class label:  2  Number: 579\n",
      "Class label:  3  Number: 590\n",
      "Class label:  4  Number: 571\n",
      "Class label:  5  Number: 577\n",
      "Class label:  6  Number: 580\n",
      "Class label:  7  Number: 570\n",
      "Class label:  8  Number: 580\n",
      "Class label:  9  Number: 586\n",
      "Class label:  10  Number: 579\n",
      "Class label:  11  Number: 190\n",
      "Class label:  12  Number: 195\n",
      "Class label:  13  Number: 196\n",
      "Class label:  14  Number: 190\n",
      "Class label:  15  Number: 190\n",
      "Class label:  16  Number: 194\n",
      "Class label:  17  Number: 193\n",
      "Class label:  18  Number: 190\n",
      "Class label:  19  Number: 193\n",
      "Class label:  20  Number: 195\n",
      "Class label:  21  Number: 98\n",
      "Class label:  22  Number: 97\n",
      "Class label:  23  Number: 97\n",
      "Class label:  24  Number: 98\n",
      "Class label:  25  Number: 96\n",
      "Class label:  26  Number: 98\n",
      "Class label:  27  Number: 98\n",
      "Class label:  28  Number: 97\n",
      "Class label:  29  Number: 97\n",
      "Class label:  30  Number: 95\n",
      "Class label:  31  Number: 49\n",
      "Class label:  32  Number: 48\n",
      "Class label:  33  Number: 49\n",
      "Class label:  34  Number: 48\n",
      "Class label:  35  Number: 48\n",
      "Class label:  36  Number: 47\n",
      "Class label:  37  Number: 49\n",
      "Class label:  38  Number: 49\n",
      "Class label:  39  Number: 48\n",
      "Class label:  40  Number: 49\n",
      "Class label:  41  Number: 24\n",
      "Class label:  42  Number: 25\n",
      "Class label:  43  Number: 24\n",
      "Class label:  44  Number: 24\n",
      "Class label:  45  Number: 24\n",
      "Class label:  46  Number: 24\n",
      "Class label:  47  Number: 24\n",
      "Class label:  48  Number: 24\n",
      "Class label:  49  Number: 24\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train = pd.read_csv(\"train.csv\", header = None)\n",
    "test = pd.read_csv(\"test.csv\", header = None)\n",
    "\n",
    "# minor_size is number of classes less than 500 instances\n",
    "minor_size = 0\n",
    "grouped = train.groupby(train.columns[-1])\n",
    "for k,group in grouped:\n",
    "        if len(group.index) < 500:\n",
    "            minor_size += 1\n",
    "        print (\"Class label: \",k,end='')\n",
    "        print(\"  Number:\",len(group.index))\n",
    "minor_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "edef5ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#from sklearn.model_selection import cross_validation\n",
    "# exclude sample ID (1st column)\n",
    "x_train_valid = train.iloc[:,1:-1].to_numpy()\n",
    "y_train_valid = train.iloc[:,-1].to_numpy()\n",
    "\n",
    "#split a validation set for hyper-parameter tuning\n",
    "split_ratio = 0.2\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train_valid, y_train_valid, test_size=split_ratio, random_state=1,stratify = y_train_valid) \n",
    "\n",
    "x_test = test.iloc[:,1:].to_numpy()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac4c49f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ada size:  25076\n",
      "bdsmt size:  22222\n",
      "smt size:  23128\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import ADASYN, BorderlineSMOTE, SMOTE\n",
    "\n",
    "# we only oversample during training\n",
    "ada = ADASYN(random_state = 42, sampling_strategy = 'minority', n_neighbors=5)\n",
    "bdsmt = BorderlineSMOTE(random_state = 42)\n",
    "smt = SMOTE(random_state = 42)\n",
    "\n",
    "x_ada_train = x_train.copy()\n",
    "y_ada_train = y_train.copy()\n",
    "x_bdsmt_train = x_train.copy()\n",
    "y_bdsmt_train = y_train.copy()\n",
    "x_smt_train = x_train.copy()\n",
    "y_smt_train = y_train.copy()\n",
    "\n",
    "# ada failed to resample all minority class at once, we manually resample minority classes(less than 500 instances)\n",
    "for i in range(minor_size):\n",
    "    x_ada_train, y_ada_train = ada.fit_resample(x_ada_train, y_ada_train)\n",
    "    \n",
    "    \n",
    "x_bdsmt_train, y_bdsmt_train = bdsmt.fit_resample(x_bdsmt_train, y_bdsmt_train)\n",
    "x_smt_train, y_smt_train = smt.fit_resample(x_smt_train, y_smt_train)\n",
    "\n",
    "print(\"ada size: \", len(y_ada_train))\n",
    "print(\"bdsmt size: \", len(y_bdsmt_train))\n",
    "print(\"smt size: \", len(y_smt_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "017456d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\npca = PCA(n_components=300)\\npca = PCA(n_components = 'mle')\\n\\nx_ada_train_pca =  pca.fit_transform(x_ada_train_norm)\\nx_bdsmt_train_pca =  pca.fit_transform(x_bdsmt_train_norm)\\nx_val_pca = pca.fit_transform(x_val_norm)\\n\\nprint(x_ada_train_pca.shape, x_bdsmt_train_pca.shape)\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# normalize data, useful when no outlier\n",
    "x_ada_train_norm = preprocessing.normalize(x_ada_train)\n",
    "x_bdsmt_train_norm = preprocessing.normalize(x_bdsmt_train)\n",
    "x_val_norm = preprocessing.normalize(x_val)\n",
    "\n",
    "# standardize data, useful when data is normally distributed\n",
    "#scaler = preprocessing.RobustScaler().fit(x_bdsmt_train)\n",
    "scaler = preprocessing.RobustScaler().fit(x_train)\n",
    "x_bdsmt_train_std = scaler.transform(x_bdsmt_train)\n",
    "x_train_std = scaler.transform(x_train)\n",
    "x_val_std = scaler.transform(x_val)\n",
    "x_test_std = scaler.transform(x_test)\n",
    "\n",
    "\n",
    "'''\n",
    "pca = PCA(n_components=300)\n",
    "pca = PCA(n_components = 'mle')\n",
    "\n",
    "x_ada_train_pca =  pca.fit_transform(x_ada_train_norm)\n",
    "x_bdsmt_train_pca =  pca.fit_transform(x_bdsmt_train_norm)\n",
    "x_val_pca = pca.fit_transform(x_val_norm)\n",
    "\n",
    "print(x_ada_train_pca.shape, x_bdsmt_train_pca.shape)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6ec8102",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22222, 365)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feature selection\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_selection import GenericUnivariateSelect, f_classif\n",
    "\n",
    "# selectfrommodel using extra tree\n",
    "clf = ExtraTreesClassifier(n_estimators=50)\n",
    "clf.fit(x_bdsmt_train, y_bdsmt_train)\n",
    "selection_model = SelectFromModel(clf, prefit=True)\n",
    "x_bdsmt_train_selected = selection_model.transform(x_bdsmt_train)\n",
    "x_val_selected = selection_model.transform(x_val)\n",
    "x_test_selected = selection_model.transform(x_test)\n",
    "x_bdsmt_train_selected.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9847bab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22222, 300)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GenericUnivariateSelect using f_classif(ANOVA f-value)\n",
    "transformer = GenericUnivariateSelect(f_classif, mode='k_best', param=300)\n",
    "transformer.fit_transform(x_bdsmt_train, y_bdsmt_train)\n",
    "x_train_tran = transformer.transform(x_train)\n",
    "x_bdsmt_train_tran = transformer.transform(x_bdsmt_train)\n",
    "x_val_tran = transformer.transform(x_val)\n",
    "x_test_tran = transformer.transform(x_test)\n",
    "x_bdsmt_train_tran.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b719075",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nattempt on SVM\\n\\nfrom sklearn.utils import class_weight\\nfrom sklearn import svm\\nfrom sklearn.metrics import accuracy_score\\nimport numpy as np\\n\\nclf_svm_weight = svm.SVC(class_weight = \"balanced\")\\nclf_svm_weight.fit(x_train, y_train)\\n\\ny_pred_weight = clf_svm_weight.predict(x_val)\\naccuracy_score(y_val, y_pred_weight)\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "attempt on SVM\n",
    "\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "clf_svm_weight = svm.SVC(class_weight = \"balanced\")\n",
    "clf_svm_weight.fit(x_train, y_train)\n",
    "\n",
    "y_pred_weight = clf_svm_weight.predict(x_val)\n",
    "accuracy_score(y_val, y_pred_weight)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "350b8ff2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nclf_svm = svm.SVC()\\nclf_svm.fit(x_bdsmt_train_std, y_bdsmt_train)\\n\\ny_pred = clf_svm.predict(x_val_std)\\naccuracy_score(y_val, y_pred)\\n\\ny_pred_test = clf_svm.predict(x_test)\\nid_svm = test.iloc[:,0].to_numpy()\\nid_svm = [(i-1) for i in id_svm]\\ndf = pd.DataFrame({\\'Id\\': id_svm, \\'Category\\': y_pred_test})\\ndf.to_csv(\"svm_output.csv\", index = False)\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "clf_svm = svm.SVC()\n",
    "clf_svm.fit(x_bdsmt_train_std, y_bdsmt_train)\n",
    "\n",
    "y_pred = clf_svm.predict(x_val_std)\n",
    "accuracy_score(y_val, y_pred)\n",
    "\n",
    "y_pred_test = clf_svm.predict(x_test)\n",
    "id_svm = test.iloc[:,0].to_numpy()\n",
    "id_svm = [(i-1) for i in id_svm]\n",
    "df = pd.DataFrame({'Id': id_svm, 'Category': y_pred_test})\n",
    "df.to_csv(\"svm_output.csv\", index = False)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c99f2c6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nimport xgboost as xgb\\nfrom hyperopt import STATUS_OK, Trials, fmin, hp, tpe\\nfrom sklearn.metrics import accuracy_score\\n\\nspace={\\n        \\'n_estimators\\': hp.quniform(\\'n_estimators\\', 50, 300, 50),\\n        \\'eta\\': hp.quniform(\\'eta\\', 0.1,0.8,0.05),\\n        \\'max_depth\\': hp.quniform(\"max_depth\", 3, 12, 1),\\n        \\'gamma\\': hp.uniform (\\'gamma\\', 0,10),\\n        \\'reg_alpha\\' : hp.quniform(\\'reg_alpha\\', 0,100,1),\\n        \\'reg_lambda\\' : hp.quniform(\\'reg_lambda\\', 0,100,1),\\n        \\'colsample_bytree\\' : hp.uniform(\\'colsample_bytree\\', 0.2,1),\\n        \\'colsample_bynode\\' : hp.uniform(\\'colsample_bynode\\', 0.2,1),\\n        \\'colsample_bylevel\\' : hp.uniform(\\'colsample_bylevel\\', 0.2,1),\\n        \\'min_child_weight\\' : hp.quniform(\\'min_child_weight\\', 0, 10, 1),\\n        \\'sampling_method\\' : hp.choice(\\'sampling_method\\', (\\'uniform\\', \\'gradient_based\\')),\\n        \\'seed\\': 0\\n    }\\n\\ndef objective(space):\\n   \\n    clf=xgb.XGBClassifier(\\n                  space, tree_method = \\'gpu_hist\\')\\n    print(\"space: \", space)\\n    \\n    evaluation = [(x_bdsmt_train, y_bdsmt_train), ( x_val, y_val)]\\n    \\n    clf.fit(x_bdsmt_train, y_bdsmt_train,\\n            eval_set=evaluation, eval_metric=\"auc\",\\n            early_stopping_rounds=15,verbose=False)\\n    \\n\\n    pred = clf.predict(x_val)\\n    #accuracy = accuracy_score(y_val, pred>0.5)\\n    accuracy = accuracy_score(y_val, pred)\\n    print (\"SCORE:\", accuracy)\\n    return {\\'loss\\': -accuracy, \\'status\\': STATUS_OK }\\n\\n\\ntrials = Trials()\\nbest_hyperparams = fmin(fn = objective,\\n                        space = space,\\n                        algo = tpe.suggest,\\n                        max_evals = 50,\\n                        trials = trials)\\nbest_hyperparams                 \\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "import xgboost as xgb\n",
    "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "space={\n",
    "        'n_estimators': hp.quniform('n_estimators', 50, 300, 50),\n",
    "        'eta': hp.quniform('eta', 0.1,0.8,0.05),\n",
    "        'max_depth': hp.quniform(\"max_depth\", 3, 12, 1),\n",
    "        'gamma': hp.uniform ('gamma', 0,10),\n",
    "        'reg_alpha' : hp.quniform('reg_alpha', 0,100,1),\n",
    "        'reg_lambda' : hp.quniform('reg_lambda', 0,100,1),\n",
    "        'colsample_bytree' : hp.uniform('colsample_bytree', 0.2,1),\n",
    "        'colsample_bynode' : hp.uniform('colsample_bynode', 0.2,1),\n",
    "        'colsample_bylevel' : hp.uniform('colsample_bylevel', 0.2,1),\n",
    "        'min_child_weight' : hp.quniform('min_child_weight', 0, 10, 1),\n",
    "        'sampling_method' : hp.choice('sampling_method', ('uniform', 'gradient_based')),\n",
    "        'seed': 0\n",
    "    }\n",
    "\n",
    "def objective(space):\n",
    "   \n",
    "    clf=xgb.XGBClassifier(\n",
    "                  space, tree_method = 'gpu_hist')\n",
    "    print(\"space: \", space)\n",
    "    \n",
    "    evaluation = [(x_bdsmt_train, y_bdsmt_train), ( x_val, y_val)]\n",
    "    \n",
    "    clf.fit(x_bdsmt_train, y_bdsmt_train,\n",
    "            eval_set=evaluation, eval_metric=\"auc\",\n",
    "            early_stopping_rounds=15,verbose=False)\n",
    "    \n",
    "\n",
    "    pred = clf.predict(x_val)\n",
    "    #accuracy = accuracy_score(y_val, pred>0.5)\n",
    "    accuracy = accuracy_score(y_val, pred)\n",
    "    print (\"SCORE:\", accuracy)\n",
    "    return {'loss': -accuracy, 'status': STATUS_OK }\n",
    "\n",
    "\n",
    "trials = Trials()\n",
    "best_hyperparams = fmin(fn = objective,\n",
    "                        space = space,\n",
    "                        algo = tpe.suggest,\n",
    "                        max_evals = 50,\n",
    "                        trials = trials)\n",
    "best_hyperparams                 \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f3c4e85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nimport xgboost as xgb\\nfrom sklearn.metrics import accuracy_score\\npara = {'colsample_bylevel': 0.7506165996395784, 'colsample_bynode': 0.47255523978411235, 'colsample_bytree': 0.6309464903602169, 'eta': 0.75, 'gamma': 0.7838134219171133, 'max_depth': 7.0, 'min_child_weight': 4.0, 'n_estimators': 150.0, 'reg_alpha': 48.0, 'reg_lambda': 44.0, 'sampling_method': 'uniform', 'seed': 0}\\nclf_xgb=xgb.XGBClassifier(para, tree_method = 'gpu_hist')\\n\\nclf_xgb.fit(x_train, y_train, verbose = True) \\ny_pred_xgb = clf_xgb.predict(x_val)\\naccuracy_score(y_val, y_pred_xgb)\\n\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "para = {'colsample_bylevel': 0.7506165996395784, 'colsample_bynode': 0.47255523978411235, 'colsample_bytree': 0.6309464903602169, 'eta': 0.75, 'gamma': 0.7838134219171133, 'max_depth': 7.0, 'min_child_weight': 4.0, 'n_estimators': 150.0, 'reg_alpha': 48.0, 'reg_lambda': 44.0, 'sampling_method': 'uniform', 'seed': 0}\n",
    "clf_xgb=xgb.XGBClassifier(para, tree_method = 'gpu_hist')\n",
    "\n",
    "clf_xgb.fit(x_train, y_train, verbose = True) \n",
    "y_pred_xgb = clf_xgb.predict(x_val)\n",
    "accuracy_score(y_val, y_pred_xgb)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "374b1af5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ny_pred_xgb = clf_xgb.predict(x_test)\\nid_svm = test.iloc[:,0].to_numpy()\\nid_svm = [(i-1) for i in id_svm]\\ndf = pd.DataFrame({\\'Id\\': id_svm, \\'Category\\': y_pred_xgb})\\ndf.to_csv(\"output_xgb.csv\", index = False)\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "y_pred_xgb = clf_xgb.predict(x_test)\n",
    "id_svm = test.iloc[:,0].to_numpy()\n",
    "id_svm = [(i-1) for i in id_svm]\n",
    "df = pd.DataFrame({'Id': id_svm, 'Category': y_pred_xgb})\n",
    "df.to_csv(\"output_xgb.csv\", index = False)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43387b74",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a26d46f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape (Reshape)            (None, 16, 60)            0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 16)                4928      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 50)                850       \n",
      "=================================================================\n",
      "Total params: 5,778\n",
      "Trainable params: 5,778\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build neural network\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import TimeDistributed, Reshape, Dropout, Flatten, LSTM, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.layers.convolutional import Conv1D, MaxPooling1D\n",
    "\n",
    "n_timesteps = 16\n",
    "n_features = 60\n",
    "'''\n",
    "dense_no = 50\n",
    "inputs_lstm = layers.Input(shape=(960,))\n",
    "    \n",
    "reshape_input = layers.Reshape((16,60), input_shape = (960,))(inputs_lstm)\n",
    "dense1 = layers.Dense(dense_no, activation=\"relu\")\n",
    "dense2 = layers.Dense(dense_no, activation=\"relu\")\n",
    "\n",
    "conv1 = Conv1D(filters=32,kernel_size=1,activation='relu', input_shape = (1,n_features))\n",
    "conv2 = Conv1D(filters=32,kernel_size=1,activation='relu')\n",
    "dense3 = layers.Dense(dense_no, activation=\"relu\")\n",
    "\n",
    "\n",
    "\n",
    "shape = reshape_input.get_shape()\n",
    "concatenate_input = []\n",
    "stack_input2 = []\n",
    "\n",
    "print(reshape_input)\n",
    "for i in range(shape[1]):\n",
    "    #print(tf.reshape(reshape_input[:,i,:], [-1,60]))\n",
    "    #concatenate_input.append(dense2(Dropout(0.2)((dense1(tf.reshape(reshape_input[:,i,:], [-1,60]))))))\n",
    "   \n",
    "    conv_input = tf.reshape(reshape_input[:,i,:], [-1, 1, 60])\n",
    "    print(conv_input.shape )\n",
    "    print(conv1(conv_input).shape)\n",
    "    conv_output = MaxPooling1D(padding = 'same')((Dropout(0.2)(conv1(conv_input))))\n",
    "    \n",
    "    print(conv_output.shape)\n",
    "    #x = MaxPooling2D((2,2), padding='same')(x)\n",
    "    conv_output = dense3(Flatten()(MaxPooling1D(padding = 'same')((Dropout(0.2)(conv2(conv_input))))))\n",
    "    \n",
    "    concatenate_input.append(conv_output)\n",
    "    \n",
    "    #stack_input2.append(tf.reshape(reshape_input[:,i,:], [-1,60]))\n",
    "print(concatenate_input )\n",
    "print(stack_input2)\n",
    "#out = Concatenate()(all_step)\n",
    "concatenate_input = Concatenate()(concatenate_input)\n",
    "print(concatenate_input.shape)\n",
    "concatenate_input = tf.reshape(concatenate_input,[-1,16,dense_no])\n",
    "x = layers.LSTM(16, dropout=0.3, input_shape = (16,60),return_sequences=True)(concatenate_input)\n",
    "x = layers.LSTM(16, dropout=0.3, input_shape = (16,60))(x)\n",
    "outputs = layers.Dense(50, activation=\"softmax\")(x)\n",
    "\n",
    "model_lstm = keras.Model(inputs = inputs_lstm, outputs = outputs)\n",
    "model_lstm.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model_lstm.summary()\n",
    "'''\n",
    "model_lstm = Sequential()\n",
    "model_lstm.add(layers.Reshape((16, 60), input_shape=(960,)))\n",
    "#model_lstm.add(layers.LSTM(16, dropout=0.15, input_shape = (16,60),return_sequences=True))\n",
    "model_lstm.add(layers.LSTM(16, dropout=0.15, input_shape = (16,60)))\n",
    "#model_lstm.add(layers.LSTM(16))\n",
    "#model_lstm.add(layers.GlobalAveragePooling1D())\n",
    "model_lstm.add(layers.Dense(50, activation=\"softmax\"))\n",
    "model_lstm.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model_lstm.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ed19cd53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "118/118 [==============================] - 2s 9ms/step - loss: 3.8266 - accuracy: 0.0623 - val_loss: 3.6977 - val_accuracy: 0.1113\n",
      "Epoch 2/100\n",
      "118/118 [==============================] - 1s 6ms/step - loss: 3.5250 - accuracy: 0.1214 - val_loss: 3.3560 - val_accuracy: 0.1278\n",
      "Epoch 3/100\n",
      "118/118 [==============================] - 1s 6ms/step - loss: 3.2271 - accuracy: 0.1610 - val_loss: 3.1722 - val_accuracy: 0.1656\n",
      "Epoch 4/100\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 3.0786 - accuracy: 0.1887 - val_loss: 3.0644 - val_accuracy: 0.1768\n",
      "Epoch 5/100\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 2.9764 - accuracy: 0.2017 - val_loss: 2.9840 - val_accuracy: 0.1896\n",
      "Epoch 6/100\n",
      "118/118 [==============================] - 1s 8ms/step - loss: 2.9001 - accuracy: 0.2146 - val_loss: 2.9297 - val_accuracy: 0.2023\n",
      "Epoch 7/100\n",
      "118/118 [==============================] - 1s 8ms/step - loss: 2.8366 - accuracy: 0.2252 - val_loss: 2.8908 - val_accuracy: 0.2114\n",
      "Epoch 8/100\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 2.7847 - accuracy: 0.2447 - val_loss: 2.8499 - val_accuracy: 0.2274\n",
      "Epoch 9/100\n",
      "118/118 [==============================] - 1s 8ms/step - loss: 2.7362 - accuracy: 0.2549 - val_loss: 2.8100 - val_accuracy: 0.2407\n",
      "Epoch 10/100\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 2.6943 - accuracy: 0.2699 - val_loss: 2.7783 - val_accuracy: 0.2455\n",
      "Epoch 11/100\n",
      "118/118 [==============================] - 1s 8ms/step - loss: 2.6501 - accuracy: 0.2802 - val_loss: 2.7518 - val_accuracy: 0.2588\n",
      "Epoch 12/100\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 2.6144 - accuracy: 0.2899 - val_loss: 2.7384 - val_accuracy: 0.2604\n",
      "Epoch 13/100\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 2.5792 - accuracy: 0.2973 - val_loss: 2.7118 - val_accuracy: 0.2678\n",
      "Epoch 14/100\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 2.5622 - accuracy: 0.3012 - val_loss: 2.6901 - val_accuracy: 0.2732\n",
      "Epoch 15/100\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 2.5272 - accuracy: 0.3129 - val_loss: 2.6702 - val_accuracy: 0.2849\n",
      "Epoch 16/100\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 2.5009 - accuracy: 0.3210 - val_loss: 2.6604 - val_accuracy: 0.2875\n",
      "Epoch 17/100\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 2.4821 - accuracy: 0.3248 - val_loss: 2.6484 - val_accuracy: 0.2875\n",
      "Epoch 18/100\n",
      "118/118 [==============================] - 1s 8ms/step - loss: 2.4566 - accuracy: 0.3318 - val_loss: 2.6341 - val_accuracy: 0.2923\n",
      "Epoch 19/100\n",
      "118/118 [==============================] - 1s 8ms/step - loss: 2.4387 - accuracy: 0.3386 - val_loss: 2.6165 - val_accuracy: 0.3009\n",
      "Epoch 20/100\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 2.4206 - accuracy: 0.3426 - val_loss: 2.6041 - val_accuracy: 0.3051\n",
      "Epoch 21/100\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 2.3991 - accuracy: 0.3447 - val_loss: 2.5936 - val_accuracy: 0.3083\n",
      "Epoch 22/100\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 2.3843 - accuracy: 0.3475 - val_loss: 2.5792 - val_accuracy: 0.3078\n",
      "Epoch 23/100\n",
      "118/118 [==============================] - 1s 8ms/step - loss: 2.3690 - accuracy: 0.3510 - val_loss: 2.5763 - val_accuracy: 0.3115\n",
      "Epoch 24/100\n",
      "118/118 [==============================] - 1s 9ms/step - loss: 2.3487 - accuracy: 0.3578 - val_loss: 2.5683 - val_accuracy: 0.3062\n",
      "Epoch 25/100\n",
      "118/118 [==============================] - 1s 9ms/step - loss: 2.3394 - accuracy: 0.3615 - val_loss: 2.5561 - val_accuracy: 0.3142\n",
      "Epoch 26/100\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 2.3245 - accuracy: 0.3646 - val_loss: 2.5512 - val_accuracy: 0.3237\n",
      "Epoch 27/100\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 2.3149 - accuracy: 0.3634 - val_loss: 2.5474 - val_accuracy: 0.3237\n",
      "Epoch 28/100\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 2.3016 - accuracy: 0.3676 - val_loss: 2.5300 - val_accuracy: 0.3259\n",
      "Epoch 29/100\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 2.2858 - accuracy: 0.3744 - val_loss: 2.5265 - val_accuracy: 0.3280\n",
      "Epoch 30/100\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 2.2815 - accuracy: 0.3688 - val_loss: 2.5284 - val_accuracy: 0.3291\n",
      "Epoch 31/100\n",
      "118/118 [==============================] - 1s 6ms/step - loss: 2.2736 - accuracy: 0.3763 - val_loss: 2.5270 - val_accuracy: 0.3237\n",
      "Epoch 32/100\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 2.2583 - accuracy: 0.3779 - val_loss: 2.5192 - val_accuracy: 0.3344\n",
      "Epoch 33/100\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 2.2566 - accuracy: 0.3794 - val_loss: 2.5129 - val_accuracy: 0.3301\n",
      "Epoch 34/100\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 2.2410 - accuracy: 0.3850 - val_loss: 2.5189 - val_accuracy: 0.3317\n",
      "Epoch 35/100\n",
      "118/118 [==============================] - 1s 8ms/step - loss: 2.2290 - accuracy: 0.3858 - val_loss: 2.5047 - val_accuracy: 0.3333\n",
      "Epoch 36/100\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 2.2184 - accuracy: 0.3925 - val_loss: 2.5035 - val_accuracy: 0.3381\n",
      "Epoch 37/100\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 2.2106 - accuracy: 0.3891 - val_loss: 2.5066 - val_accuracy: 0.3307\n",
      "Epoch 38/100\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 2.2083 - accuracy: 0.3905 - val_loss: 2.5043 - val_accuracy: 0.3312\n",
      "Epoch 39/100\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 2.1988 - accuracy: 0.3957 - val_loss: 2.5084 - val_accuracy: 0.3413\n",
      "Epoch 40/100\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 2.1983 - accuracy: 0.3988 - val_loss: 2.5057 - val_accuracy: 0.3424\n",
      "Epoch 41/100\n",
      "118/118 [==============================] - 1s 8ms/step - loss: 2.1870 - accuracy: 0.3964 - val_loss: 2.4964 - val_accuracy: 0.3392\n",
      "Epoch 42/100\n",
      "118/118 [==============================] - 1s 8ms/step - loss: 2.1719 - accuracy: 0.4025 - val_loss: 2.4993 - val_accuracy: 0.3365\n",
      "Epoch 43/100\n",
      "118/118 [==============================] - 1s 8ms/step - loss: 2.1695 - accuracy: 0.4009 - val_loss: 2.4935 - val_accuracy: 0.3323\n",
      "Epoch 44/100\n",
      "118/118 [==============================] - 1s 8ms/step - loss: 2.1524 - accuracy: 0.4081 - val_loss: 2.4894 - val_accuracy: 0.3456\n",
      "Epoch 45/100\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 2.1578 - accuracy: 0.4061 - val_loss: 2.4831 - val_accuracy: 0.3413\n",
      "Epoch 46/100\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 2.1527 - accuracy: 0.4057 - val_loss: 2.4856 - val_accuracy: 0.3413\n",
      "Epoch 47/100\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 2.1434 - accuracy: 0.4080 - val_loss: 2.4883 - val_accuracy: 0.3413\n",
      "Epoch 48/100\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 2.1308 - accuracy: 0.4107 - val_loss: 2.4781 - val_accuracy: 0.3392\n",
      "Epoch 49/100\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 2.1313 - accuracy: 0.4132 - val_loss: 2.4714 - val_accuracy: 0.3472\n",
      "Epoch 50/100\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 2.1206 - accuracy: 0.4157 - val_loss: 2.4741 - val_accuracy: 0.3498\n",
      "Epoch 51/100\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 2.1049 - accuracy: 0.4162 - val_loss: 2.4792 - val_accuracy: 0.3450\n",
      "Epoch 52/100\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 2.1100 - accuracy: 0.4169 - val_loss: 2.4839 - val_accuracy: 0.3429\n",
      "Epoch 53/100\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 2.1173 - accuracy: 0.4148 - val_loss: 2.4771 - val_accuracy: 0.3440\n",
      "Epoch 54/100\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 2.1027 - accuracy: 0.4186 - val_loss: 2.4695 - val_accuracy: 0.3408\n",
      "Epoch 55/100\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 2.0970 - accuracy: 0.4176 - val_loss: 2.4832 - val_accuracy: 0.3403\n",
      "Epoch 56/100\n",
      "118/118 [==============================] - 1s 8ms/step - loss: 2.0974 - accuracy: 0.4194 - val_loss: 2.4755 - val_accuracy: 0.3456\n",
      "Epoch 57/100\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 2.0856 - accuracy: 0.4214 - val_loss: 2.4647 - val_accuracy: 0.3557\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100\n",
      "118/118 [==============================] - ETA: 0s - loss: 2.0808 - accuracy: 0.42 - 1s 7ms/step - loss: 2.0808 - accuracy: 0.4241 - val_loss: 2.4709 - val_accuracy: 0.3493\n",
      "Epoch 59/100\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 2.0810 - accuracy: 0.4225 - val_loss: 2.4833 - val_accuracy: 0.3445\n",
      "Epoch 60/100\n",
      "118/118 [==============================] - 1s 8ms/step - loss: 2.0750 - accuracy: 0.4314 - val_loss: 2.4756 - val_accuracy: 0.3472\n",
      "Epoch 61/100\n",
      "118/118 [==============================] - 1s 8ms/step - loss: 2.0673 - accuracy: 0.4233 - val_loss: 2.4616 - val_accuracy: 0.3472\n",
      "Epoch 62/100\n",
      "118/118 [==============================] - 1s 8ms/step - loss: 2.0604 - accuracy: 0.4300 - val_loss: 2.4785 - val_accuracy: 0.3482\n",
      "Epoch 63/100\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 2.0647 - accuracy: 0.4274 - val_loss: 2.4820 - val_accuracy: 0.3504\n",
      "Epoch 64/100\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 2.0586 - accuracy: 0.4314 - val_loss: 2.4810 - val_accuracy: 0.3546\n",
      "Epoch 65/100\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 2.0491 - accuracy: 0.4354 - val_loss: 2.4848 - val_accuracy: 0.3525\n",
      "Epoch 66/100\n",
      "118/118 [==============================] - 1s 6ms/step - loss: 2.0513 - accuracy: 0.4308 - val_loss: 2.4753 - val_accuracy: 0.3514\n",
      "Epoch 67/100\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 2.0488 - accuracy: 0.4362 - val_loss: 2.4928 - val_accuracy: 0.3482\n",
      "Epoch 68/100\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 2.0444 - accuracy: 0.4354 - val_loss: 2.4792 - val_accuracy: 0.3509\n",
      "Epoch 69/100\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 2.0382 - accuracy: 0.4333 - val_loss: 2.4790 - val_accuracy: 0.3520\n",
      "Epoch 70/100\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 2.0327 - accuracy: 0.4383 - val_loss: 2.4727 - val_accuracy: 0.3568\n",
      "Epoch 71/100\n",
      "118/118 [==============================] - 1s 6ms/step - loss: 2.0320 - accuracy: 0.4411 - val_loss: 2.4811 - val_accuracy: 0.3514\n",
      "Epoch 72/100\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 2.0265 - accuracy: 0.4345 - val_loss: 2.4746 - val_accuracy: 0.3493\n",
      "Epoch 73/100\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 2.0243 - accuracy: 0.4390 - val_loss: 2.4710 - val_accuracy: 0.3482\n",
      "Epoch 74/100\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 2.0189 - accuracy: 0.4433 - val_loss: 2.4870 - val_accuracy: 0.3536\n",
      "Epoch 75/100\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 2.0145 - accuracy: 0.4445 - val_loss: 2.4740 - val_accuracy: 0.3562\n",
      "Epoch 76/100\n",
      "118/118 [==============================] - 1s 6ms/step - loss: 2.0202 - accuracy: 0.4393 - val_loss: 2.4825 - val_accuracy: 0.3562\n",
      "Epoch 77/100\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 2.0117 - accuracy: 0.4415 - val_loss: 2.4717 - val_accuracy: 0.3509\n",
      "Epoch 78/100\n",
      "118/118 [==============================] - 1s 8ms/step - loss: 2.0054 - accuracy: 0.4459 - val_loss: 2.4736 - val_accuracy: 0.3568\n",
      "Epoch 79/100\n",
      "118/118 [==============================] - 1s 8ms/step - loss: 2.0089 - accuracy: 0.4443 - val_loss: 2.4826 - val_accuracy: 0.3562\n",
      "Epoch 80/100\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 2.0070 - accuracy: 0.4423 - val_loss: 2.4758 - val_accuracy: 0.3568\n",
      "Epoch 81/100\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 2.0059 - accuracy: 0.4446 - val_loss: 2.4707 - val_accuracy: 0.3562\n",
      "Epoch 82/100\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 2.0011 - accuracy: 0.4466 - val_loss: 2.4780 - val_accuracy: 0.3541\n",
      "Epoch 83/100\n",
      "118/118 [==============================] - 1s 6ms/step - loss: 1.9959 - accuracy: 0.4499 - val_loss: 2.4795 - val_accuracy: 0.3578\n",
      "Epoch 84/100\n",
      "118/118 [==============================] - 1s 6ms/step - loss: 1.9913 - accuracy: 0.4463 - val_loss: 2.4797 - val_accuracy: 0.3552\n",
      "Epoch 85/100\n",
      "118/118 [==============================] - 1s 6ms/step - loss: 1.9939 - accuracy: 0.4438 - val_loss: 2.4740 - val_accuracy: 0.3573\n",
      "Epoch 86/100\n",
      "118/118 [==============================] - 1s 6ms/step - loss: 1.9891 - accuracy: 0.4502 - val_loss: 2.4730 - val_accuracy: 0.3541\n",
      "Epoch 87/100\n",
      "118/118 [==============================] - 1s 6ms/step - loss: 1.9903 - accuracy: 0.4470 - val_loss: 2.4770 - val_accuracy: 0.3552\n",
      "Epoch 88/100\n",
      "118/118 [==============================] - 1s 6ms/step - loss: 1.9742 - accuracy: 0.4550 - val_loss: 2.4770 - val_accuracy: 0.3541\n",
      "Epoch 89/100\n",
      "118/118 [==============================] - 1s 6ms/step - loss: 1.9761 - accuracy: 0.4513 - val_loss: 2.4754 - val_accuracy: 0.3605\n",
      "Epoch 90/100\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 1.9801 - accuracy: 0.4543 - val_loss: 2.4911 - val_accuracy: 0.3541\n",
      "Epoch 91/100\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 1.9720 - accuracy: 0.4459 - val_loss: 2.4778 - val_accuracy: 0.3482\n",
      "Epoch 92/100\n",
      "118/118 [==============================] - 1s 8ms/step - loss: 1.9767 - accuracy: 0.4523 - val_loss: 2.4753 - val_accuracy: 0.3594\n",
      "Epoch 93/100\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 1.9718 - accuracy: 0.4491 - val_loss: 2.4764 - val_accuracy: 0.3568\n",
      "Epoch 94/100\n",
      "118/118 [==============================] - 1s 6ms/step - loss: 1.9636 - accuracy: 0.4559 - val_loss: 2.4839 - val_accuracy: 0.3568\n",
      "Epoch 95/100\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 1.9556 - accuracy: 0.4569 - val_loss: 2.4902 - val_accuracy: 0.3600\n",
      "Epoch 96/100\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 1.9618 - accuracy: 0.4607 - val_loss: 2.4847 - val_accuracy: 0.3573\n",
      "Epoch 97/100\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 1.9440 - accuracy: 0.4603 - val_loss: 2.4902 - val_accuracy: 0.3520\n",
      "Epoch 98/100\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 1.9562 - accuracy: 0.4573 - val_loss: 2.4961 - val_accuracy: 0.3621\n",
      "Epoch 99/100\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 1.9546 - accuracy: 0.4591 - val_loss: 2.4857 - val_accuracy: 0.3594\n",
      "Epoch 100/100\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 1.9525 - accuracy: 0.4581 - val_loss: 2.4832 - val_accuracy: 0.3541\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1dcf3ec09d0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lstm.fit(x_train_std,y_train, epochs=100, batch_size=64, verbose=True, validation_data=(x_val_std, y_val))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "32c9cee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lstm = model_lstm.predict(x_test_std)\n",
    "\n",
    "y_pred_lstm = [np.argmax(i) for i in y_pred_lstm]\n",
    "\n",
    "id_lstm = test.iloc[:,0].to_numpy()\n",
    "id_lstm = [(i-1) for i in id_lstm]\n",
    "df = pd.DataFrame({'Id': id_lstm, 'Category': y_pred_lstm})\n",
    "df.to_csv(\"output_lstm.csv\", index = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0886b7dc",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c6a9d78c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape_1 (Reshape)          (None, 16, 60)            0         \n",
      "_________________________________________________________________\n",
      "module_wrapper (ModuleWrappe (None, 16, 32)            1952      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 16, 32)            0         \n",
      "_________________________________________________________________\n",
      "module_wrapper_1 (ModuleWrap (None, 8, 32)             0         \n",
      "_________________________________________________________________\n",
      "module_wrapper_2 (ModuleWrap (None, 8, 32)             1056      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 8, 32)             0         \n",
      "_________________________________________________________________\n",
      "module_wrapper_3 (ModuleWrap (None, 4, 32)             0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 50)                1650      \n",
      "=================================================================\n",
      "Total params: 8,786\n",
      "Trainable params: 8,786\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import Model, Input\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, Reshape, Concatenate\n",
    "from keras.layers.convolutional import Conv1D, MaxPooling1D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "n_timesteps = 16\n",
    "n_features = 60\n",
    "ff_out = 50\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Reshape((n_timesteps,n_features), input_shape = (960,)))\n",
    "model.add(Conv1D(filters=32,kernel_size=1,activation='relu', input_shape=(n_timesteps,n_features)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Conv1D(filters=32, kernel_size=1, activation='relu'))\n",
    "#model.add(Conv1D(filters=32, kernel_size=1, activation='relu'))\n",
    "#odel.add(Conv1D(filters=32, kernel_size=1, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(50, activation='softmax'))\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7d854f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 3.9702 - accuracy: 0.0889 - val_loss: 3.5514 - val_accuracy: 0.1273\n",
      "Epoch 2/100\n",
      "118/118 [==============================] - 0s 3ms/step - loss: 3.4130 - accuracy: 0.1447 - val_loss: 3.3250 - val_accuracy: 0.1597\n",
      "Epoch 3/100\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 3.2144 - accuracy: 0.1771 - val_loss: 3.1371 - val_accuracy: 0.1896\n",
      "Epoch 4/100\n",
      "118/118 [==============================] - 0s 3ms/step - loss: 3.0254 - accuracy: 0.1961 - val_loss: 2.9916 - val_accuracy: 0.2018\n",
      "Epoch 5/100\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 2.8851 - accuracy: 0.2233 - val_loss: 2.8867 - val_accuracy: 0.2242\n",
      "Epoch 6/100\n",
      "118/118 [==============================] - 0s 3ms/step - loss: 2.7813 - accuracy: 0.2437 - val_loss: 2.8013 - val_accuracy: 0.2449\n",
      "Epoch 7/100\n",
      "118/118 [==============================] - 0s 3ms/step - loss: 2.6969 - accuracy: 0.2687 - val_loss: 2.7463 - val_accuracy: 0.2657\n",
      "Epoch 8/100\n",
      "118/118 [==============================] - 0s 3ms/step - loss: 2.6213 - accuracy: 0.2884 - val_loss: 2.6752 - val_accuracy: 0.2737\n",
      "Epoch 9/100\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 2.5410 - accuracy: 0.3069 - val_loss: 2.6257 - val_accuracy: 0.2993\n",
      "Epoch 10/100\n",
      "118/118 [==============================] - 0s 3ms/step - loss: 2.4807 - accuracy: 0.3206 - val_loss: 2.5826 - val_accuracy: 0.3142\n",
      "Epoch 11/100\n",
      "118/118 [==============================] - 0s 3ms/step - loss: 2.4168 - accuracy: 0.3333 - val_loss: 2.5461 - val_accuracy: 0.3184\n",
      "Epoch 12/100\n",
      "118/118 [==============================] - 0s 3ms/step - loss: 2.3804 - accuracy: 0.3461 - val_loss: 2.5149 - val_accuracy: 0.3285\n",
      "Epoch 13/100\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 2.3214 - accuracy: 0.3562 - val_loss: 2.4749 - val_accuracy: 0.3413\n",
      "Epoch 14/100\n",
      "118/118 [==============================] - 0s 3ms/step - loss: 2.2894 - accuracy: 0.3634 - val_loss: 2.4582 - val_accuracy: 0.3461\n",
      "Epoch 15/100\n",
      "118/118 [==============================] - 0s 3ms/step - loss: 2.2449 - accuracy: 0.3832 - val_loss: 2.4400 - val_accuracy: 0.3440\n",
      "Epoch 16/100\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 2.2069 - accuracy: 0.3903 - val_loss: 2.4259 - val_accuracy: 0.3429\n",
      "Epoch 17/100\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 2.1791 - accuracy: 0.3947 - val_loss: 2.4087 - val_accuracy: 0.3573\n",
      "Epoch 18/100\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 2.1515 - accuracy: 0.4025 - val_loss: 2.3925 - val_accuracy: 0.3541\n",
      "Epoch 19/100\n",
      "118/118 [==============================] - 0s 3ms/step - loss: 2.1278 - accuracy: 0.4065 - val_loss: 2.3794 - val_accuracy: 0.3562\n",
      "Epoch 20/100\n",
      "118/118 [==============================] - 0s 3ms/step - loss: 2.1029 - accuracy: 0.4148 - val_loss: 2.3729 - val_accuracy: 0.3600\n",
      "Epoch 21/100\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 2.0775 - accuracy: 0.4128 - val_loss: 2.3607 - val_accuracy: 0.3711\n",
      "Epoch 22/100\n",
      "118/118 [==============================] - 0s 3ms/step - loss: 2.0638 - accuracy: 0.4273 - val_loss: 2.3552 - val_accuracy: 0.3743\n",
      "Epoch 23/100\n",
      "118/118 [==============================] - 0s 3ms/step - loss: 2.0540 - accuracy: 0.4253 - val_loss: 2.3480 - val_accuracy: 0.3695\n",
      "Epoch 24/100\n",
      "118/118 [==============================] - 0s 3ms/step - loss: 2.0372 - accuracy: 0.4221 - val_loss: 2.3331 - val_accuracy: 0.3781\n",
      "Epoch 25/100\n",
      "118/118 [==============================] - 0s 3ms/step - loss: 2.0113 - accuracy: 0.4378 - val_loss: 2.3386 - val_accuracy: 0.3738\n",
      "Epoch 26/100\n",
      "118/118 [==============================] - 0s 3ms/step - loss: 2.0040 - accuracy: 0.4375 - val_loss: 2.3460 - val_accuracy: 0.3663\n",
      "Epoch 27/100\n",
      "118/118 [==============================] - 0s 3ms/step - loss: 1.9852 - accuracy: 0.4451 - val_loss: 2.3366 - val_accuracy: 0.3765\n",
      "Epoch 28/100\n",
      "118/118 [==============================] - 0s 3ms/step - loss: 1.9643 - accuracy: 0.4482 - val_loss: 2.3244 - val_accuracy: 0.3759\n",
      "Epoch 29/100\n",
      "118/118 [==============================] - 0s 3ms/step - loss: 1.9628 - accuracy: 0.4495 - val_loss: 2.3195 - val_accuracy: 0.3834\n",
      "Epoch 30/100\n",
      "118/118 [==============================] - 0s 3ms/step - loss: 1.9410 - accuracy: 0.4555 - val_loss: 2.3186 - val_accuracy: 0.3770\n",
      "Epoch 31/100\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 1.9375 - accuracy: 0.4566 - val_loss: 2.3042 - val_accuracy: 0.3860\n",
      "Epoch 32/100\n",
      "118/118 [==============================] - ETA: 0s - loss: 1.9058 - accuracy: 0.45 - 0s 3ms/step - loss: 1.9171 - accuracy: 0.4537 - val_loss: 2.3032 - val_accuracy: 0.3940\n",
      "Epoch 33/100\n",
      "118/118 [==============================] - 0s 3ms/step - loss: 1.9098 - accuracy: 0.4640 - val_loss: 2.3129 - val_accuracy: 0.3860\n",
      "Epoch 34/100\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 1.8944 - accuracy: 0.4644 - val_loss: 2.2919 - val_accuracy: 0.3855\n",
      "Epoch 35/100\n",
      "118/118 [==============================] - 0s 3ms/step - loss: 1.8926 - accuracy: 0.4643 - val_loss: 2.2970 - val_accuracy: 0.3839\n",
      "Epoch 36/100\n",
      "118/118 [==============================] - 0s 3ms/step - loss: 1.8787 - accuracy: 0.4678 - val_loss: 2.2935 - val_accuracy: 0.3802\n",
      "Epoch 37/100\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 1.8784 - accuracy: 0.4700 - val_loss: 2.2984 - val_accuracy: 0.3850\n",
      "Epoch 38/100\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 1.8661 - accuracy: 0.4690 - val_loss: 2.2906 - val_accuracy: 0.3860\n",
      "Epoch 39/100\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 1.8565 - accuracy: 0.4786 - val_loss: 2.2975 - val_accuracy: 0.3855\n",
      "Epoch 40/100\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 1.8434 - accuracy: 0.4790 - val_loss: 2.3015 - val_accuracy: 0.3882\n",
      "Epoch 41/100\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 1.8293 - accuracy: 0.4779 - val_loss: 2.3182 - val_accuracy: 0.3892\n",
      "Epoch 42/100\n",
      "118/118 [==============================] - 0s 3ms/step - loss: 1.8315 - accuracy: 0.4755 - val_loss: 2.3029 - val_accuracy: 0.3855\n",
      "Epoch 43/100\n",
      "118/118 [==============================] - 0s 3ms/step - loss: 1.8114 - accuracy: 0.4856 - val_loss: 2.2940 - val_accuracy: 0.3940\n",
      "Epoch 44/100\n",
      "118/118 [==============================] - 0s 3ms/step - loss: 1.8107 - accuracy: 0.4851 - val_loss: 2.2880 - val_accuracy: 0.3930\n",
      "Epoch 45/100\n",
      "118/118 [==============================] - 0s 3ms/step - loss: 1.8037 - accuracy: 0.4900 - val_loss: 2.2853 - val_accuracy: 0.3940\n",
      "Epoch 46/100\n",
      "118/118 [==============================] - 0s 3ms/step - loss: 1.7901 - accuracy: 0.4915 - val_loss: 2.3014 - val_accuracy: 0.3908\n",
      "Epoch 47/100\n",
      "118/118 [==============================] - 0s 3ms/step - loss: 1.8043 - accuracy: 0.4888 - val_loss: 2.2834 - val_accuracy: 0.3951\n",
      "Epoch 48/100\n",
      "118/118 [==============================] - 0s 3ms/step - loss: 1.7759 - accuracy: 0.4960 - val_loss: 2.2944 - val_accuracy: 0.3930\n",
      "Epoch 49/100\n",
      "118/118 [==============================] - 0s 3ms/step - loss: 1.7759 - accuracy: 0.4976 - val_loss: 2.2857 - val_accuracy: 0.4020\n",
      "Epoch 50/100\n",
      "118/118 [==============================] - 0s 3ms/step - loss: 1.7654 - accuracy: 0.4916 - val_loss: 2.2947 - val_accuracy: 0.3978\n",
      "Epoch 51/100\n",
      "118/118 [==============================] - 0s 3ms/step - loss: 1.7660 - accuracy: 0.4955 - val_loss: 2.3111 - val_accuracy: 0.3951\n",
      "Epoch 52/100\n",
      "118/118 [==============================] - 0s 3ms/step - loss: 1.7480 - accuracy: 0.5080 - val_loss: 2.2956 - val_accuracy: 0.4004\n",
      "Epoch 53/100\n",
      "118/118 [==============================] - 0s 3ms/step - loss: 1.7558 - accuracy: 0.4979 - val_loss: 2.2947 - val_accuracy: 0.3967\n",
      "Epoch 54/100\n",
      "118/118 [==============================] - 0s 3ms/step - loss: 1.7563 - accuracy: 0.4985 - val_loss: 2.3077 - val_accuracy: 0.3967\n",
      "Epoch 55/100\n",
      "118/118 [==============================] - 0s 3ms/step - loss: 1.7443 - accuracy: 0.5041 - val_loss: 2.2999 - val_accuracy: 0.3972\n",
      "Epoch 56/100\n",
      "118/118 [==============================] - 0s 3ms/step - loss: 1.7391 - accuracy: 0.5072 - val_loss: 2.2931 - val_accuracy: 0.3994\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118/118 [==============================] - 0s 3ms/step - loss: 1.7314 - accuracy: 0.5063 - val_loss: 2.2798 - val_accuracy: 0.4031\n",
      "Epoch 58/100\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 1.7164 - accuracy: 0.5096 - val_loss: 2.2834 - val_accuracy: 0.4058\n",
      "Epoch 59/100\n",
      "118/118 [==============================] - 0s 3ms/step - loss: 1.7125 - accuracy: 0.5093 - val_loss: 2.3001 - val_accuracy: 0.4031\n",
      "Epoch 60/100\n",
      "118/118 [==============================] - 0s 3ms/step - loss: 1.7042 - accuracy: 0.5134 - val_loss: 2.3071 - val_accuracy: 0.3994\n",
      "Epoch 61/100\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 1.7021 - accuracy: 0.5053 - val_loss: 2.3166 - val_accuracy: 0.4063\n",
      "Epoch 62/100\n",
      "118/118 [==============================] - 0s 3ms/step - loss: 1.6970 - accuracy: 0.5124 - val_loss: 2.2941 - val_accuracy: 0.4127\n",
      "Epoch 63/100\n",
      "118/118 [==============================] - ETA: 0s - loss: 1.6883 - accuracy: 0.51 - 0s 3ms/step - loss: 1.6996 - accuracy: 0.5158 - val_loss: 2.3000 - val_accuracy: 0.3988\n",
      "Epoch 64/100\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 1.6782 - accuracy: 0.5189 - val_loss: 2.3081 - val_accuracy: 0.4058\n",
      "Epoch 65/100\n",
      "118/118 [==============================] - 0s 3ms/step - loss: 1.6829 - accuracy: 0.5212 - val_loss: 2.2931 - val_accuracy: 0.4068\n",
      "Epoch 66/100\n",
      "118/118 [==============================] - 0s 3ms/step - loss: 1.6868 - accuracy: 0.5182 - val_loss: 2.3004 - val_accuracy: 0.4116\n",
      "Epoch 67/100\n",
      "118/118 [==============================] - 0s 3ms/step - loss: 1.6966 - accuracy: 0.5108 - val_loss: 2.2839 - val_accuracy: 0.4063\n",
      "Epoch 68/100\n",
      "118/118 [==============================] - 0s 3ms/step - loss: 1.6702 - accuracy: 0.5269 - val_loss: 2.3015 - val_accuracy: 0.4127\n",
      "Epoch 69/100\n",
      "118/118 [==============================] - 0s 3ms/step - loss: 1.6766 - accuracy: 0.5213 - val_loss: 2.3194 - val_accuracy: 0.4073\n",
      "Epoch 70/100\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 1.6626 - accuracy: 0.5281 - val_loss: 2.3008 - val_accuracy: 0.4079\n",
      "Epoch 71/100\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 1.6604 - accuracy: 0.5220 - val_loss: 2.3141 - val_accuracy: 0.4026\n",
      "Epoch 72/100\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 1.6580 - accuracy: 0.5229 - val_loss: 2.2931 - val_accuracy: 0.4105\n",
      "Epoch 73/100\n",
      "118/118 [==============================] - 0s 3ms/step - loss: 1.6514 - accuracy: 0.5236 - val_loss: 2.3052 - val_accuracy: 0.4143\n",
      "Epoch 74/100\n",
      "118/118 [==============================] - 0s 3ms/step - loss: 1.6587 - accuracy: 0.5232 - val_loss: 2.3064 - val_accuracy: 0.4164\n",
      "Epoch 75/100\n",
      "118/118 [==============================] - 0s 3ms/step - loss: 1.6530 - accuracy: 0.5221 - val_loss: 2.3080 - val_accuracy: 0.4148\n",
      "Epoch 76/100\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 1.6495 - accuracy: 0.5244 - val_loss: 2.3150 - val_accuracy: 0.4084\n",
      "Epoch 77/100\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 1.6326 - accuracy: 0.5341 - val_loss: 2.3298 - val_accuracy: 0.4127\n",
      "Epoch 78/100\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 1.6439 - accuracy: 0.5246 - val_loss: 2.3186 - val_accuracy: 0.4111\n",
      "Epoch 79/100\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 1.6324 - accuracy: 0.5356 - val_loss: 2.3280 - val_accuracy: 0.4100\n",
      "Epoch 80/100\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 1.6334 - accuracy: 0.5233 - val_loss: 2.3136 - val_accuracy: 0.4228\n",
      "Epoch 81/100\n",
      "118/118 [==============================] - 0s 3ms/step - loss: 1.6271 - accuracy: 0.5322 - val_loss: 2.3031 - val_accuracy: 0.4164\n",
      "Epoch 82/100\n",
      "118/118 [==============================] - 0s 3ms/step - loss: 1.6249 - accuracy: 0.5322 - val_loss: 2.3155 - val_accuracy: 0.4201\n",
      "Epoch 83/100\n",
      "118/118 [==============================] - 0s 3ms/step - loss: 1.6249 - accuracy: 0.5368 - val_loss: 2.3171 - val_accuracy: 0.4116\n",
      "Epoch 84/100\n",
      "118/118 [==============================] - 0s 3ms/step - loss: 1.6233 - accuracy: 0.5369 - val_loss: 2.3273 - val_accuracy: 0.4180\n",
      "Epoch 85/100\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 1.6331 - accuracy: 0.5274 - val_loss: 2.3271 - val_accuracy: 0.4164\n",
      "Epoch 86/100\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 1.6264 - accuracy: 0.5302 - val_loss: 2.3162 - val_accuracy: 0.4201\n",
      "Epoch 87/100\n",
      "118/118 [==============================] - 0s 3ms/step - loss: 1.6239 - accuracy: 0.5286 - val_loss: 2.3229 - val_accuracy: 0.4185\n",
      "Epoch 88/100\n",
      "118/118 [==============================] - 0s 3ms/step - loss: 1.6077 - accuracy: 0.5369 - val_loss: 2.3242 - val_accuracy: 0.4137\n",
      "Epoch 89/100\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 1.5969 - accuracy: 0.5370 - val_loss: 2.3316 - val_accuracy: 0.4212\n",
      "Epoch 90/100\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 1.6125 - accuracy: 0.5298 - val_loss: 2.3280 - val_accuracy: 0.4153\n",
      "Epoch 91/100\n",
      "118/118 [==============================] - 0s 3ms/step - loss: 1.6028 - accuracy: 0.5350 - val_loss: 2.3187 - val_accuracy: 0.4255\n",
      "Epoch 92/100\n",
      "118/118 [==============================] - 0s 3ms/step - loss: 1.5979 - accuracy: 0.5364 - val_loss: 2.3213 - val_accuracy: 0.4228\n",
      "Epoch 93/100\n",
      "118/118 [==============================] - 0s 3ms/step - loss: 1.5829 - accuracy: 0.5451 - val_loss: 2.3366 - val_accuracy: 0.4201\n",
      "Epoch 94/100\n",
      "118/118 [==============================] - 0s 3ms/step - loss: 1.5973 - accuracy: 0.5403 - val_loss: 2.3175 - val_accuracy: 0.4143\n",
      "Epoch 95/100\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 1.5849 - accuracy: 0.5422 - val_loss: 2.3419 - val_accuracy: 0.4116\n",
      "Epoch 96/100\n",
      "118/118 [==============================] - 0s 3ms/step - loss: 1.5941 - accuracy: 0.5477 - val_loss: 2.3191 - val_accuracy: 0.4196\n",
      "Epoch 97/100\n",
      "118/118 [==============================] - 0s 3ms/step - loss: 1.5797 - accuracy: 0.5366 - val_loss: 2.3129 - val_accuracy: 0.4239\n",
      "Epoch 98/100\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 1.5789 - accuracy: 0.5442 - val_loss: 2.3286 - val_accuracy: 0.4185\n",
      "Epoch 99/100\n",
      "118/118 [==============================] - 0s 3ms/step - loss: 1.5827 - accuracy: 0.5415 - val_loss: 2.3389 - val_accuracy: 0.4111\n",
      "Epoch 100/100\n",
      "118/118 [==============================] - 0s 3ms/step - loss: 1.5752 - accuracy: 0.5383 - val_loss: 2.3218 - val_accuracy: 0.4233\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1dcfc4995b0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " model.fit(x_train_std,y_train, epochs=100, batch_size=64, verbose=True, validation_data=(x_val_std, y_val))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fc921ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_pred_cnn = model.predict(x_test_std)\n",
    "\n",
    "y_pred_cnn = [np.argmax(i) for i in y_pred_cnn]\n",
    "\n",
    "id_cnn = test.iloc[:,0].to_numpy()\n",
    "id_cnn = [(i-1) for i in id_cnn]\n",
    "df = pd.DataFrame({'Id': id_cnn, 'Category': y_pred_cnn})\n",
    "df.to_csv(\"output_cnn.csv\", index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9538be16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
