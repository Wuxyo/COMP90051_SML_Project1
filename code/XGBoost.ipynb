{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key \"text.kerning_factor\" on line 4 in\n",
      "/Users/apple/miniconda3/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test_patch.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "http://github.com/matplotlib/matplotlib/blob/master/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# check version number\n",
    "import imblearn\n",
    "print(imblearn.__version__)\n",
    "\n",
    "from collections import Counter\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "#warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "train = pd.read_csv(\"train.csv\", header = None)\n",
    "\n",
    "test = pd.read_csv(\"test.csv\", header = None)\n",
    "\n",
    "#print(test.info())\n",
    "#train.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# minor_size is number of classes less than 500 instances\n",
    "minor_size = 0\n",
    "grouped = train.groupby(train.columns[-1])\n",
    "for k,group in grouped:\n",
    "        if len(group.index) < 500:\n",
    "            minor_size += 1\n",
    "        #print (\"Class label: \",k,end='')\n",
    "        #print(\"  Number:\",len(group.index), end='')\n",
    "        #print(\" (%.3f%%)\" %  float(len(group.index)/len(train)*100))\n",
    "minor_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exclude sample ID (1st column)\n",
    "x_train_valid = train.iloc[:,1:-1].to_numpy()\n",
    "y_train_valid = train.iloc[:,-1].to_numpy()\n",
    "\n",
    "#split a validation set for hyper-parameter tuning\n",
    "split_ratio = 0.2\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train_valid, y_train_valid, test_size=split_ratio, random_state=1,stratify = y_train_valid) \n",
    "\n",
    "x_test = test.iloc[:,1:].to_numpy()\n",
    "#y_test = test.iloc[:,-1].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ada size:  25076\n",
      "bdsmt size:  22222\n",
      "smt size:  23128\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import ADASYN, BorderlineSMOTE, SMOTE\n",
    "\n",
    "# we only oversample during training\n",
    "ada = ADASYN(random_state = 42, sampling_strategy = 'minority', n_neighbors=5)\n",
    "bdsmt = BorderlineSMOTE(random_state = 42)\n",
    "smt = SMOTE(random_state = 42)\n",
    "\n",
    "x_ada_train = x_train.copy()\n",
    "y_ada_train = y_train.copy()\n",
    "\n",
    "x_bdsmt_train = x_train.copy()\n",
    "y_bdsmt_train = y_train.copy()\n",
    "\n",
    "x_smt_train = x_train.copy()\n",
    "y_smt_train = y_train.copy()\n",
    "\n",
    "# ada failed to resample all minority class at once, we manually resample minority classes(less than 500 instances)\n",
    "for i in range(minor_size):\n",
    "    x_ada_train, y_ada_train = ada.fit_resample(x_ada_train, y_ada_train)\n",
    "    \n",
    "    \n",
    "x_bdsmt_train, y_bdsmt_train = bdsmt.fit_resample(x_bdsmt_train, y_bdsmt_train)\n",
    "x_smt_train, y_smt_train = smt.fit_resample(x_smt_train, y_smt_train)\n",
    "\n",
    "#print(\"ada size: \", len(x_ada_train))\n",
    "#print(\"bdsmt size: \", len(x_bdsmt_train))\n",
    "print(\"ada size: \", len(y_ada_train))\n",
    "print(\"bdsmt size: \", len(y_bdsmt_train))\n",
    "print(\"smt size: \", len(y_smt_train))\n",
    "\n",
    "\n",
    "counter = Counter(y_bdsmt_train)\n",
    "for k,v in counter.items():\n",
    "    per = v / len(y_bdsmt_train) * 100\n",
    "    #print('Class=%d, n=%d (%.3f%%)' % (k, v, per))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### xgboost\n",
    "\n",
    "- option 1: XGBClassifier applies on BDLine_SMOTE data (sampling method)\n",
    "    - BDLine_SMOTE perform the best\n",
    "- option 2: XGBClassifier applies on unbalanced data with weight (cost sensitive method)\n",
    "    - 2.1 scale_pos_weight\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "import sklearn.metrics as metrics\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_Accuracy_Data = pd.DataFrame(columns = ['option','n_estimators','max_depth','random_state',\n",
    "                                             'min_child_weight','gamma','learning_rate', 'eta'\n",
    "                                             'subsample','colsample_bytree','n_jobs','Train ACC','Val ACC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainStartTime = time.time()\n",
    "\n",
    "option = 'option 1'\n",
    "\n",
    "# Number of trees\n",
    "n_estimators = 50\n",
    "\n",
    "# Maximum number of levels in tree\n",
    "max_depth = 5\n",
    "\n",
    "random_state = 0\n",
    "\n",
    "#minimum sum of weights of all observations required in a child\n",
    "min_child_weight = 2\n",
    "\n",
    "#Gamma specifies the minimum loss reduction required to make a split\n",
    "gamma = 0\n",
    "\n",
    "# boosting learning rate\n",
    "learning_rate = 0.01\n",
    "\n",
    "subsample = 0.8 # 80% of data to grow trees and prevent overfitting\n",
    "\n",
    "colsample_bytree = 0.80  # 85% of features used\n",
    "\n",
    "eta = 0.1\n",
    "\n",
    "n_jobs = -1\n",
    "\n",
    "\n",
    "\n",
    "xgb = XGBClassifier(n_estimators=n_estimators, max_depth=max_depth,\n",
    "                    random_state = random_state, min_child_weight = min_child_weight,\n",
    "                    gamma = gamma, learning_rate = learning_rate, subsample = subsample,\n",
    "                    colsample_bytree = colsample_bytree, eta = eta, n_jobs = n_jobs)\n",
    "\n",
    "\n",
    "model= xgb.fit(x_bdsmt_train, y_bdsmt_train)\n",
    "\n",
    "Test_Accuracy_Data_One = pd.DataFrame(index = range(1),columns = ['option','n_estimators','max_depth','random_state',\n",
    "                                                                  'min_child_weight','gamma','learning_rate', 'eta',\n",
    "                                                                  'subsample','colsample_bytree','n_jobs',\n",
    "                                                                  'Train ACC','Val ACC'])\n",
    "\n",
    "Test_Accuracy_Data_One.loc[:,'option'] = option\n",
    "Test_Accuracy_Data_One.loc[:,'n_estimators'] = n_estimators\n",
    "Test_Accuracy_Data_One.loc[:,'max_depth'] = max_depth\n",
    "Test_Accuracy_Data_One.loc[:,'random_state'] = random_state            \n",
    "Test_Accuracy_Data_One.loc[:,'min_child_weight'] = min_child_weight\n",
    "Test_Accuracy_Data_One.loc[:,'gamma'] = gamma\n",
    "Test_Accuracy_Data_One.loc[:,'learning_rate'] = learning_rate       \n",
    "Test_Accuracy_Data_One.loc[:,'eta'] = eta\n",
    "Test_Accuracy_Data_One.loc[:,'subsample'] = subsample\n",
    "Test_Accuracy_Data_One.loc[:,'colsample_bytree'] = colsample_bytree\n",
    "Test_Accuracy_Data_One.loc[:,'n_jobs'] = n_jobs\n",
    "\n",
    "\n",
    "train_pre = xgb.predict(x_bdsmt_train)\n",
    "train_acc = xgb.score(x_bdsmt_train, y_bdsmt_train)\n",
    "train_acc1 = accuracy_score(y_bdsmt_train, train_pre)\n",
    "\n",
    "predictions = xgb.predict(x_val)\n",
    "acc = xgb.score(x_val, y_val)\n",
    "acc1 = accuracy_score(y_val, predictions)\n",
    "\n",
    "Test_Accuracy_Data_One.loc[:,'Train ACC'] = train_acc\n",
    "Test_Accuracy_Data_One.loc[:,'Val ACC'] = acc \n",
    "\n",
    "Test_Accuracy_Data = Test_Accuracy_Data.append(Test_Accuracy_Data_One)\n",
    "            \n",
    "print(train_acc1)\n",
    "print(acc1)\n",
    "\n",
    "trainFinishTime = time.time()\n",
    "print(\"Time spent on training is: \" + str(trainFinishTime - trainStartTime) + \" sec\")\n",
    "\n",
    "Test_Accuracy_Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output Final Result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test on the test data\n",
    "predictions=xgb.predict(x_test)\n",
    "\n",
    "with open(\"xgb_out.csv\",\"w\", newline=\"\") as csvfile:\n",
    "    writer=csv.writer(csvfile)\n",
    "    writer.writerow([\"Id\",\"Category\"])\n",
    "    test_id = 0\n",
    "    for pred in predictions:\n",
    "        writer.writerow([test_id, pred])\n",
    "        test_id+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
